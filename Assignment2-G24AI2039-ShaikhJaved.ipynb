{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqb1NxTuspB8hs6vK5LsbL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaikhjavedofficial/IITJ/blob/main/Assignment2-G24AI2039-ShaikhJaved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "mlr02X49McR3"
      },
      "outputs": [],
      "source": [
        "# --- Initialization ---\n",
        "%%capture\n",
        "# Install Hadoop (pseudo-distributed) & mrjob, fetch datasets for reproducibility.\n",
        "!pip install mrjob\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "# --- Download datasets ---\n",
        "!wget -O cruise.csv \"https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/cruise.csv\"\n",
        "!wget -O customer_churn.csv \"https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/customer_churn.csv\"\n",
        "!wget -O ecom_customer.csv \"https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/e-com_customer.csv\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. Cruiseline Aggregations\n",
        "\n",
        "For each Cruise Line in `cruise.csv`, compute:\n",
        "- Total number of ships,\n",
        "- Average Tonnage (rounded to 2 decimals),\n",
        "- Maximum crew size.\n",
        "\n",
        "Implemented using `mrjob`, with Combiner for efficiency.\n"
      ],
      "metadata": {
        "id": "XY5D52_USJB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q1_test_data = \"\"\"Ship_name,Cruise_line,Age,Tonnage,passengers,length,cabins,passenger_density,crew\n",
        "Journey,Azamara,6,30.276999999999997,6.94,5.94,3.55,42.64,3.55\n",
        "Quest,Azamara,6,30.276999999999997,6.94,5.94,3.55,42.64,3.55\n",
        "Celebration,Carnival,26,47.262,14.86,7.22,7.43,31.8,6.7\n",
        "Conquest,Carnival,11,110.0,29.74,9.53,14.88,36.99,19.1\n",
        "Destiny,Carnival,17,101.353,26.42,8.92,13.21,38.36,10.0\n",
        "Ecstasy,Carnival,22,70.367,20.52,8.55,10.2,34.29,9.2\n",
        "Elation,Carnival,15,70.367,20.52,8.55,10.2,34.29,9.2\n",
        "Fantasy,Carnival,23,70.367,20.56,8.55,10.22,34.23,9.2\n",
        "Fascination,Carnival,19,70.367,20.52,8.55,10.2,34.29,9.2\n",
        "Freedom,Carnival,6,110.23899999999999,37.0,9.51,14.87,29.79,11.5\n",
        "\"\"\"\n",
        "with open(\"q1_test.csv\", \"w\") as f: f.write(q1_test_data)\n"
      ],
      "metadata": {
        "id": "FY9GfNkGWDe_"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file CruiseLineAgg.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "\n",
        "class CruiseLineAgg(MRJob):\n",
        "    \"\"\"\n",
        "    MapReduce job to compute:\n",
        "    - Total ships, average tonnage, and max crew per Cruise Line.\n",
        "    Usage:\n",
        "      !python CruiseLineAgg.py cruise.csv\n",
        "    \"\"\"\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        row = next(csv.reader([line]))\n",
        "        if row[0] == \"Ship_name\":  # skip header\n",
        "            return\n",
        "        cruise_line = row[1]\n",
        "        tonnage = float(row[2])\n",
        "        crew = float(row[4])\n",
        "        yield cruise_line, (1, tonnage, crew)\n",
        "\n",
        "    def combiner(self, cruise_line, values):\n",
        "        count = 0\n",
        "        ton_sum = 0.0\n",
        "        max_crew = 0.0\n",
        "        for ships, ton, crew in values:\n",
        "            count += ships\n",
        "            ton_sum += ton\n",
        "            max_crew = max(max_crew, crew)\n",
        "        yield cruise_line, (count, ton_sum, max_crew)\n",
        "\n",
        "    def reducer(self, cruise_line, values):\n",
        "        count = 0\n",
        "        ton_sum = 0.0\n",
        "        max_crew = 0.0\n",
        "        for ships, ton, crew in values:\n",
        "            count += ships\n",
        "            ton_sum += ton\n",
        "            max_crew = max(max_crew, crew)\n",
        "        avg_ton = round(ton_sum / count, 2)\n",
        "        yield cruise_line, {\"ships\": count, \"avg_tonnage\": avg_ton, \"max_crew\": max_crew}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    CruiseLineAgg.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kidnk6L4R6q2",
        "outputId": "da24fe2d-3f35-4681-ae84-e3cfbc29e78c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CruiseLineAgg.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST RUN ON SMALL DATA\n",
        "!python3 CruiseLineAgg.py q1_test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO6O-avPSZrE",
        "outputId": "9f9fa302-ceb9-4a74-e910-cca36acbb3d3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/CruiseLineAgg.root.20250729.180521.520229\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/CruiseLineAgg.root.20250729.180521.520229/output\n",
            "Streaming final output from /tmp/CruiseLineAgg.root.20250729.180521.520229/output...\n",
            "\"Azamara\"\t{\"ships\": 2, \"avg_tonnage\": 6.0, \"max_crew\": 6.94}\n",
            "\"Carnival\"\t{\"ships\": 8, \"avg_tonnage\": 17.38, \"max_crew\": 37.0}\n",
            "Removing temp directory /tmp/CruiseLineAgg.root.20250729.180521.520229...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2. Company Churn Rate\n",
        "Description\n",
        "Input: `customer_churn.csv`\n",
        "\n",
        "For each company, output: churn rate = CHURNED / TOTAL, float (4 decimals)\n",
        "\n",
        "Only output for companies in VIP list.\n",
        "\n",
        "Use MultiStepJob:\n",
        "\n",
        "Step1: Map company, (churned and total)\n",
        "\n",
        "Step2: Compute rates, filter using VIP file in distributed cache"
      ],
      "metadata": {
        "id": "GlHjeVizYvNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q2_test_data = \"\"\"Names,Age,Total_Purchase,Account_Manager,Years,Num_Sites,Onboard_date,Location,Company,Churn\n",
        "Cameron Williams,42.0,11066.8,0,7.22,8.0,2013-08-30 07:00:40,\"10265 Elizabeth Mission Barkerburgh, AK 89518\",Harvey LLC,1\n",
        "Kevin Mueller,41.0,11916.22,0,6.5,11.0,2013-08-13 00:38:46,\"6157 Frank Gardens Suite 019 Carloshaven, RI 17756\",Wilson PLC,1\n",
        "Eric Lozano,38.0,12884.75,0,6.67,12.0,2016-06-29 06:20:07,\"1331 Keith Court Alyssahaven, DE 90114\",\"Miller, Johnson and Wallace\",1\n",
        "Phillip White,42.0,8010.76,0,6.71,10.0,2014-04-22 12:43:12,\"13120 Daniel Mount Angelabury, WY 30645-4695\",Smith Inc,1\n",
        "Cynthia Norton,37.0,9191.58,0,5.56,9.0,2016-01-19 15:31:15,\"765 Tricia Row Karenshire, MH 71730\",Love-Jones,1\n",
        "Michael Lam,40.0,7675.52,1,4.31,11.0,2012-05-27 00:16:23,\"63714 Sawyer Glens New Tonimouth, FL 73286-2490\",Olson-Davis,0\n",
        "Nancy Thompson,36.0,13308.01,0,5.07,8.0,2009-01-20 00:52:46,\"847 Holly Loaf Apt. 839 East Nancyberg, DC 64194-2557\",Garcia-Mckinney,0\n",
        "Steve Lewis,37.0,7961.21,0,2.91,9.0,2014-06-12 12:47:15,\"865 Mitchell Causeway Suite 183 Meredithshire, AR 80502-3040\",Clarke-Gonzalez,0\n",
        "Jessica Williams,48.0,10356.02,0,5.12,8.0,2009-03-03 23:13:37,\"6187 Olson Mountains East Vincentborough, PR 74359\",Kelly-Warren,1\n",
        "Eric Butler,44.0,11331.58,1,5.23,11.0,2016-12-05 03:35:43,\"4846 Savannah Road West Justin, IA 87713-3460\",Reynolds-Sheppard,1\n",
        "Zachary Walsh,32.0,9885.12,1,6.92,9.0,2006-03-09 14:50:20,\"25271 Roy Expressway Suite 147 Brownport, FM 59852-6150\",Singh-Cole,1\n",
        "\"\"\"\n",
        "with open(\"q2_test.csv\", \"w\") as f: f.write(q2_test_data)\n",
        "with open(\"VIP_companies.txt\", \"w\") as f: f.write(\"Harvey LLC\\nWilson PLC\\nSmith Inc\\nMiller, Johnson and Wallace\\nReynolds-Sheppard\")\n"
      ],
      "metadata": {
        "id": "ju4modoUZiX3"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file CompanyChurnRate.py\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "\n",
        "class CompanyChurnRate(MRJob):\n",
        "    \"\"\"For each company in VIP_companies.txt, output churn rate to 4 decimals.\"\"\"\n",
        "    FILES = ['VIP_companies.txt']\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper=self.mapper_get_counts,\n",
        "                   reducer=self.reducer_aggregate),\n",
        "            MRStep(reducer_init=self.reducer_init,\n",
        "                   reducer=self.reducer_churn_rate)\n",
        "        ]\n",
        "\n",
        "    def mapper_get_counts(self, _, line):\n",
        "        try:\n",
        "            row = next(csv.reader([line]))\n",
        "            # skip lines that do not have at least 3 columns\n",
        "            if len(row) < 10:\n",
        "                return\n",
        "            # skip header or any rows where churn is not '0' or '1'\n",
        "            if row[9] not in ('0', '1'):\n",
        "                return\n",
        "            company = row[8]\n",
        "            churn = int(row[9])\n",
        "            # yield company with counts: (1 for total, churn status 0 or 1)\n",
        "            yield company, (1, churn)\n",
        "        except Exception:\n",
        "            return\n",
        "\n",
        "    def reducer_aggregate(self, company, values):\n",
        "        total = 0\n",
        "        churned = 0\n",
        "        for cnt, ch in values:\n",
        "            total += cnt\n",
        "            churned += ch\n",
        "        # yield company with total customers and churned customers\n",
        "        yield company, (total, churned)\n",
        "\n",
        "    def reducer_init(self):\n",
        "        # Load VIP companies in set for filtering results\n",
        "        with open(\"VIP_companies.txt\") as f:\n",
        "            self.vipset = set(line.strip() for line in f if line.strip())\n",
        "\n",
        "    def reducer_churn_rate(self, company, vals):\n",
        "        for total, churned in vals:\n",
        "            if company in self.vipset:\n",
        "                rate = churned / total if total else 0.0\n",
        "                # yield company with churn rate rounded to 4 decimals\n",
        "                yield company, round(rate, 4)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import sys\n",
        "    from io import StringIO\n",
        "    import contextlib\n",
        "    import json\n",
        "\n",
        "    if len(sys.argv) > 1:\n",
        "      mr_job = CompanyChurnRate(args=sys.argv[1:])\n",
        "      with mr_job.make_runner() as runner:\n",
        "          runner.run()  # Run the MRJob\n",
        "          for line in runner.cat_output():\n",
        "            line = line.decode('utf-8')  # convert bytes → string\n",
        "            line = line.strip()\n",
        "            if not line or '\\t' not in line:\n",
        "              continue  # skip empty lines\n",
        "            line = line.decode('utf-8') if isinstance(line, bytes) else line\n",
        "            try:\n",
        "                key, value = line.split('\\t',1)\n",
        "                print(f\"{key}: {value}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to decode line: {line!r} — {e}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Please provide input file(s) as command line arguments.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US3aMKK8Zz5Z",
        "outputId": "2867c2ae-decf-47df-fb35-c6c688a46638"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CompanyChurnRate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 CompanyChurnRate.py q2_test.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj2rx5B_Z5m0",
        "outputId": "9fb640ec-5687-4a6a-c653-97743abf2267"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs specified for inline runner\n",
            "\"Miller, Johnson and Wallace\": 1.0\n",
            "\"Reynolds-Sheppard\": 1.0\n",
            "\"Smith Inc\": 1.0\n",
            "\"Wilson PLC\": 1.0\n",
            "\"Harvey LLC\": 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3. State-wise Spending\n",
        "\n",
        "Extract state from address (e.g., \"123 Main St, Houston, TX 77002\")\n",
        "\n",
        "For each STATE, sum Yearly Amount Spent, output top 5 by total spending."
      ],
      "metadata": {
        "id": "mQP37Xb6zV-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q3_test_data = \"\"\"Email,Address,Avatar,Avg Session Length,Time on App,Time on Website,Length of Membership,Yearly Amount Spent\n",
        "mstephenson@fernandez.com,\"835 Frank TunnelWrightmouth, MI 82180-9605\",Violet,34.49726772511229,12.65565114916675,39.57766801952616,4.0826206329529615,587.9510539684005\n",
        "hduke@hotmail.com,\"4547 Archer CommonDiazchester, CA 06566-8576\",DarkGreen,31.92627202636016,11.109460728682564,37.268958868297744,2.66403418213262,392.2049334443264\n",
        "pallen@yahoo.com,\"24645 Valerie Unions Suite 582Cobbborough, DC 99414-7564\",Bisque,33.000914755642675,11.330278057777512,37.110597442120856,4.104543202376424,487.54750486747207\n",
        "riverarebecca@gmail.com,\"1414 David ThroughwayPort Jason, OH 22070-1220\",SaddleBrown,34.30555662975554,13.717513665142507,36.72128267790313,3.120178782748092,581.8523440352177\n",
        "mstephens@davidson-herman.com,\"14023 Rodriguez PassagePort Jacobville, PR 37242-1057\",MediumAquaMarine,33.33067252364639,12.795188551078114,37.53665330059473,4.446308318351434,599.4060920457634\n",
        "alvareznancy@lucas.biz,\"645 Martha Park Apt. 611Jeffreychester, MN 67218-7250\",FloralWhite,33.871037879341976,12.026925339755056,34.47687762925054,5.493507201364199,637.102447915074\n",
        "katherine20@yahoo.com,\"68388 Reyes Lights Suite 692Josephbury, WV 92213-0247\",DarkSlateBlue,32.02159550138701,11.366348309710526,36.68377615286961,4.685017246570912,521.5721747578274\n",
        "awatkins@yahoo.com,Unit 6538 Box 8980DPO AP 09026-4941,Aqua,32.739142938380326,12.35195897300293,37.37335885854755,4.4342734348999375,549.9041461052942\n",
        "vchurch@walter-martinez.com,\"860 Lee KeyWest Debra, SD 97450-0495\",Salmon,33.98777289568564,13.386235275676436,37.534497341555735,3.2734335777477144,570.2004089636196\n",
        "bonnie69@lin.biz,\"PSC 2734, Box 5255APO AA 98456-7482\",Brown,31.936548618448917,11.814128294972196,37.14516822352819,3.202806071553459,427.1993848953282\n",
        "\"\"\"\n",
        "with open(\"q3_test.csv\", \"w\") as f: f.write(q3_test_data)\n"
      ],
      "metadata": {
        "id": "kNqmSVRuzk9O"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file StateSpendingTop5.py\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "\n",
        "class StateSpendingTop5(MRJob):\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        row = next(csv.reader([line]))\n",
        "        if row[0] == \"Email\": return\n",
        "        address = row[1]\n",
        "        try:\n",
        "            # State code is second-last after ','\n",
        "            state = address.strip().split(\",\")[-2].strip().split()[-1]\n",
        "            spent = float(row[7])\n",
        "            yield state, spent\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    def reducer(self, state, amounts):\n",
        "        yield None, (state, sum(amounts))\n",
        "\n",
        "    def reducer_find_top5(self, _, state_amounts):\n",
        "        # state_amounts: iterable of (state, total)\n",
        "        top5 = sorted(state_amounts, key=lambda x: x[1], reverse=True)[:5]\n",
        "        for state, total in top5:\n",
        "            yield state, round(total, 2)\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper=self.mapper,\n",
        "                   reducer=self.reducer),\n",
        "            MRStep(reducer=self.reducer_find_top5)\n",
        "        ]\n",
        "if __name__ == '__main__':\n",
        "    import sys\n",
        "    from io import StringIO\n",
        "    import contextlib\n",
        "    import json\n",
        "\n",
        "    if len(sys.argv) > 1:\n",
        "      mr_job = StateSpendingTop5(args=sys.argv[1:])\n",
        "      with mr_job.make_runner() as runner:\n",
        "          runner.run()  # Run the MRJob\n",
        "          for line in runner.cat_output():\n",
        "            line = line.decode('utf-8')  # convert bytes → string\n",
        "            line = line.strip()\n",
        "            if not line or '\\t' not in line:\n",
        "              continue  # skip empty lines\n",
        "            line = line.decode('utf-8') if isinstance(line, bytes) else line\n",
        "          try:\n",
        "            key, value = line.split('\\t',1)\n",
        "            print(f\"{key}: {value}\")\n",
        "          except Exception as e:\n",
        "            print(f\"Failed to decode line: {line!r} — {e}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Please provide input file(s) as command line arguments.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL0MAZCBzoQF",
        "outputId": "5c6fef84-e1f9-43dd-b6fb-cdc89a6ed9ee"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting StateSpendingTop5.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 StateSpendingTop5.py q3_test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvEwmVwr0HpL",
        "outputId": "4afc1d69-2d65-4aca-84cf-8de766201d77"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs specified for inline runner\n",
            "\"Debra\": 570.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q4. Two-step Ship Filter & Median Length\n",
        "\n",
        "Step 1: Filter all ships with passenger density > 35.0, emit ⟨cruise line, length⟩\n",
        "\n",
        "Step 2: For each cruise line, compute median length\n",
        "\n",
        "Output 2 decimals; handle even/odd number of values\n",
        "\n"
      ],
      "metadata": {
        "id": "nqSV-bzH0PQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q4_test_data = \"\"\"Ship_name,Cruise_line,Age,Tonnage,passengers,length,cabins,passenger_density,crew\n",
        "Journey,Azamara,6,30.276999999999997,6.94,5.94,3.55,42.64,3.55\n",
        "Quest,Azamara,6,30.276999999999997,6.94,5.94,3.55,42.64,3.55\n",
        "Celebration,Carnival,26,47.262,14.86,7.22,7.43,31.8,6.7\n",
        "Conquest,Carnival,11,110.0,29.74,9.53,14.88,36.99,19.1\n",
        "Destiny,Carnival,17,101.353,26.42,8.92,13.21,38.36,10.0\n",
        "Ecstasy,Carnival,22,70.367,20.52,8.55,10.2,34.29,9.2\n",
        "Elation,Carnival,15,70.367,20.52,8.55,10.2,34.29,9.2\n",
        "Fantasy,Carnival,23,70.367,20.56,8.55,10.22,34.23,9.2\n",
        "Fascination,Carnival,19,70.367,20.52,8.55,10.2,34.29,9.2\n",
        "Freedom,Carnival,6,110.23899999999999,37.0,9.51,14.87,29.79,11.5\n",
        "\"\"\"\n",
        "## Compute density = passengers/(tonnage/100)\n",
        "## line A: 200/10=20\n",
        "## line C: 60/15=4\n",
        "## line E: 36/8=4.5\n",
        "## line B: 30/13=2.31\n",
        "## line D: 30/6=5\n",
        "with open(\"q4_test.csv\", \"w\") as f: f.write(q4_test_data)\n"
      ],
      "metadata": {
        "id": "4R-WNcNo0UwY"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file ShipDensityMedian.py\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "\n",
        "class ShipDensityMedian(MRJob):\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper=self.mapper_filter_density,\n",
        "                   reducer=self.reducer_gather_lengths),\n",
        "            MRStep(reducer=self.reducer_median)\n",
        "        ]\n",
        "\n",
        "    def mapper_filter_density(self, _, line):\n",
        "        row = next(csv.reader([line]))\n",
        "        if row[0] == \"Ship_name\": return\n",
        "        cruise_line = row[1]\n",
        "        tonnage = float(row[3])\n",
        "        passengers = float(row[4])\n",
        "        length = float(row[5])\n",
        "        density = passengers / (tonnage/100)\n",
        "        if density > 35.0:\n",
        "            yield cruise_line, length\n",
        "\n",
        "    def reducer_gather_lengths(self, cruise_line, lengths):\n",
        "        # Pass all lengths as a list for median calculation\n",
        "        yield cruise_line, list(lengths)\n",
        "\n",
        "    def reducer_median(self, cruise_line, lengths_list):\n",
        "        # lengths_list will be (list_of_lengths,)\n",
        "        for lengths in lengths_list:\n",
        "            L = sorted(lengths)\n",
        "            n = len(L)\n",
        "            if n==0:\n",
        "                continue\n",
        "            if n%2==1:\n",
        "                median = L[n//2]\n",
        "            else:\n",
        "                median = (L[n//2-1]+L[n//2])/2\n",
        "            yield cruise_line, round(median,2)\n",
        "if __name__ == '__main__':\n",
        "    import sys\n",
        "    from io import StringIO\n",
        "    import contextlib\n",
        "    import json\n",
        "\n",
        "    if len(sys.argv) > 1:\n",
        "      mr_job = ShipDensityMedian(args=sys.argv[1:])\n",
        "      with mr_job.make_runner() as runner:\n",
        "          runner.run()  # Run the MRJob\n",
        "          for line in runner.cat_output():\n",
        "            line = line.decode('utf-8')  # convert bytes → string\n",
        "            line = line.strip()\n",
        "            if not line or '\\t' not in line:\n",
        "              continue  # skip empty lines\n",
        "            line = line.decode('utf-8') if isinstance(line, bytes) else line\n",
        "            try:\n",
        "              key, value = line.split('\\t',1)\n",
        "              print(f\"{key}: {value}\")\n",
        "            except Exception as e:\n",
        "              print(f\"Failed to decode line: {line!r} — {e}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Please provide input file(s) as command line arguments.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8zHhwWm0XTv",
        "outputId": "af0fd0aa-2ad8-4f4b-a8e8-131d55e0a216"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ShipDensityMedian.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ShipDensityMedian.py q4_test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArCqaCAq0ZLg",
        "outputId": "3e8efb96-e6fd-4292-aa8f-8bb13bbec257"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs specified for inline runner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Q1 Final Output:\")\n",
        "!python3 CruiseLineAgg.py cruise.csv | head -20\n",
        "\n",
        "print(\"\\nQ2 Final Output (provide your real VIP companies list!):\")\n",
        "!python3 CompanyChurnRate.py customer_churn.csv | head -10\n",
        "\n",
        "print(\"\\nQ3 Final Output:\")\n",
        "!python3 StateSpendingTop5.py ecom_customer.csv\n",
        "\n",
        "print(\"\\nQ4 Final Output:\")\n",
        "!python3 ShipDensityMedian.py cruise.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz_d_TGk0a_Z",
        "outputId": "3829c4fa-b1ad-49ab-eb2e-d80713393932"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 Final Output:\n",
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/CruiseLineAgg.root.20250729.181722.521079\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/CruiseLineAgg.root.20250729.181722.521079/output\n",
            "Streaming final output from /tmp/CruiseLineAgg.root.20250729.181722.521079/output...\n",
            "\"Disney\"\t{\"ships\": 2, \"avg_tonnage\": 14.5, \"max_crew\": 17.5}\n",
            "\"Holland_American\"\t{\"ships\": 14, \"avg_tonnage\": 17.07, \"max_crew\": 21.04}\n",
            "\"MSC\"\t{\"ships\": 8, \"avg_tonnage\": 15.12, \"max_crew\": 39.59}\n",
            "\"Norwegian\"\t{\"ships\": 13, \"avg_tonnage\": 17.46, \"max_crew\": 23.94}\n",
            "\"Oceania\"\t{\"ships\": 3, \"avg_tonnage\": 14.33, \"max_crew\": 6.84}\n",
            "\"Orient\"\t{\"ships\": 1, \"avg_tonnage\": 48.0, \"max_crew\": 8.26}\n",
            "\"P&O\"\t{\"ships\": 6, \"avg_tonnage\": 14.0, \"max_crew\": 35.74}\n",
            "\"Princess\"\t{\"ships\": 17, \"avg_tonnage\": 12.94, \"max_crew\": 37.82}\n",
            "\"Regent_Seven_Seas\"\t{\"ships\": 5, \"avg_tonnage\": 15.8, \"max_crew\": 7.0}\n",
            "\"Royal_Caribbean\"\t{\"ships\": 23, \"avg_tonnage\": 13.65, \"max_crew\": 54.0}\n",
            "\"Seabourn\"\t{\"ships\": 3, \"avg_tonnage\": 24.0, \"max_crew\": 2.08}\n",
            "\"Silversea\"\t{\"ships\": 4, \"avg_tonnage\": 15.75, \"max_crew\": 3.88}\n",
            "\"Star\"\t{\"ships\": 6, \"avg_tonnage\": 19.17, \"max_crew\": 19.6}\n",
            "\"Windstar\"\t{\"ships\": 3, \"avg_tonnage\": 25.0, \"max_crew\": 3.08}\n",
            "\"Azamara\"\t{\"ships\": 2, \"avg_tonnage\": 6.0, \"max_crew\": 6.94}\n",
            "\"Carnival\"\t{\"ships\": 22, \"avg_tonnage\": 15.23, \"max_crew\": 37.0}\n",
            "\"Celebrity\"\t{\"ships\": 10, \"avg_tonnage\": 13.7, \"max_crew\": 28.5}\n",
            "\"Costa\"\t{\"ships\": 11, \"avg_tonnage\": 16.18, \"max_crew\": 38.0}\n",
            "\"Crystal\"\t{\"ships\": 2, \"avg_tonnage\": 14.0, \"max_crew\": 10.8}\n",
            "\"Cunard\"\t{\"ships\": 3, \"avg_tonnage\": 20.0, \"max_crew\": 26.2}\n",
            "Removing temp directory /tmp/CruiseLineAgg.root.20250729.181722.521079...\n",
            "\n",
            "Q2 Final Output (provide your real VIP companies list!):\n",
            "No configs specified for inline runner\n",
            "\"Harvey LLC\": 1.0\n",
            "\"Miller, Johnson and Wallace\": 1.0\n",
            "\"Reynolds-Sheppard\": 1.0\n",
            "\"Smith Inc\": 1.0\n",
            "\"Wilson PLC\": 0.3333\n",
            "\n",
            "Q3 Final Output:\n",
            "No configs specified for inline runner\n",
            "\"Jessica\": 1352.54\n",
            "\n",
            "Q4 Final Output:\n",
            "No configs specified for inline runner\n",
            "\"MSC\": 6.05\n",
            "\"Norwegian\": 6.91\n",
            "\"Orient\": 5.78\n",
            "\"Royal_Caribbean\": 8.8\n",
            "\"Star\": 6.25\n",
            "\"Celebrity\": 2.96\n",
            "\"Holland_American\": 7.04\n"
          ]
        }
      ]
    }
  ]
}